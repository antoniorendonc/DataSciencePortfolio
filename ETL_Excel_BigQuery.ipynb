{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfLCkKeWpjOqKAWvG9uzfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniorendonc/DataSciencePortfolio/blob/main/ETL_Excel_BigQuery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ-E2bQKTOOv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Inicio del proceso ETL para cargar un archivo de Excel a BigQuery\n",
        "# Antonio Rendon\n",
        "# LinkedIn: https://www.linkedin.com/in/antoniorendon/\n",
        "# Video: (URL del video si está disponible)\n",
        "\n",
        "# EXTRACT\n",
        "# Cargar el dataset desde un archivo de Excel, omitiendo las primeras 4 filas\n",
        "df = pd.read_excel('/content/Adidas US Sales Datasets.xlsx', skiprows=4)\n",
        "\n",
        "# Revisar las dimensiones iniciales del DataFrame para verificar la carga correcta\n",
        "print(\"Dimensiones iniciales del DataFrame:\", df.shape)\n",
        "print(\"Primeras filas del DataFrame:\", df.head())\n",
        "\n",
        "# TRANSFORM\n",
        "# Eliminar columnas innecesarias que no aportan a nuestro análisis\n",
        "df.drop(['Unnamed: 0', 'Retailer ID'], axis=1, inplace=True)\n",
        "\n",
        "# Renombrar columnas para hacer los nombres más claros y comprensibles\n",
        "df.rename(columns={\n",
        "    'Invoice Date': 'InvDate',\n",
        "    'Price per Unit': 'PPU',\n",
        "    'Units Sold': 'USold',\n",
        "    'Total Sales': 'TotalSales',\n",
        "    'Operating Profit': 'OpProfit',\n",
        "    'Operating Margin': 'Margin',\n",
        "    'Sales Method': 'Chanel'\n",
        "}, inplace=True)\n",
        "\n",
        "# Convertir la columna de fecha de factura a formato de fecha simple\n",
        "df['InvDate'] = df['InvDate'].dt.date\n",
        "\n",
        "# Ajustar los valores de TotalSales y OpProfit dividiéndolos por 10 para normalización\n",
        "df['TotalSales'] = df['TotalSales'] / 10\n",
        "df['OpProfit'] = df['OpProfit'] / 10\n",
        "\n",
        "# LOAD\n",
        "# Autenticación de usuario para Google Cloud, necesario para interactuar con BigQuery\n",
        "auth.authenticate_user()\n",
        "print('Usuario autenticado')\n",
        "\n",
        "# Configuración del cliente de BigQuery con el proyecto específico\n",
        "client = bigquery.Client(project='adidas-project-415820')\n",
        "\n",
        "# Configuración para la carga de datos en BigQuery, con la opción de sobrescribir datos existentes\n",
        "job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "\n",
        "# Cargar los datos transformados en BigQuery, especificando la tabla de destino\n",
        "table_id = 'adidas_ds.sales_2020_2021'\n",
        "job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
        "job.result()  # Esperar a que la carga se complete\n",
        "\n",
        "# Verificar el estado del trabajo de carga para confirmar la finalización exitosa\n",
        "if job.state == 'DONE' and job.error_result is None:\n",
        "    print(\"La carga se completó exitosamente.\")\n",
        "else:\n",
        "    print(\"El trabajo no se completó exitosamente. Errores:\")\n",
        "    for error in job.errors:\n",
        "        print(error)\n",
        "\n",
        "# VALIDATION\n",
        "# Comparar el número de filas en el DataFrame original y en la tabla de BigQuery para validar la carga\n",
        "table = client.get_table(table_id)  # Obtener detalles de la tabla en BigQuery\n",
        "num_filas_df = df.shape[0]\n",
        "\n",
        "if table.num_rows == num_filas_df:\n",
        "    print(f\"La carga fue exitosa. El DataFrame y la tabla en BigQuery tienen {num_filas_df} filas.\")\n",
        "else:\n",
        "    print(f\"Posible discrepancia en la carga. El DataFrame tiene {num_filas_df} filas, pero la tabla en BigQuery tiene {table.num_rows} filas.\")\n"
      ]
    }
  ]
}